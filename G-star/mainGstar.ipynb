{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fa6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------\n",
      "Tolerances:  {'continuity': 0.1, 'angular': 15, 'polygon_intersection': 0.7, 'circle_intersection_ratio': 0.5}\n",
      "Euclidean Upper Bound (No Obstacles):  16.0\n",
      "Dubins Upper Bound (No Obstacles):  17.27956949581917\n",
      "### Solving Euclidean Lower Bound ###\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4468/2864698309.py:79: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
      "  Map = pkl.load(m)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "from graphutils import Graph_Gstar\n",
    "from Gstar import GstarPaths, PlotGstar\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Set the time limit for the algorithm to execute\n",
    "    timeLimit = 600\n",
    "\n",
    "    # Set the initial number of sectors and starting and ending configurations\n",
    "    initial_Sectors = 3\n",
    "    start_conf = (0, 4.5, 0)\n",
    "    end_conf = (16, 4.5, 0)\n",
    "\n",
    "    # Specify whether the heading is restricted or not\n",
    "    heading_restricted = True\n",
    "\n",
    "    # Specify the list of radii to use for the algorithm\n",
    "    radius_list = [1]\n",
    "\n",
    "    # Specify the paths to the instance files\n",
    "    instance_paths = ['./instances/map1']\n",
    "\n",
    "    # Loop through each instance path\n",
    "    for path in instance_paths:\n",
    "        # Load the tolerances for this instance from the YAML file\n",
    "        with open(path+'/tolerances.yaml') as toleances_yaml:\n",
    "            tolerances = yaml.load(toleances_yaml, Loader=yaml.FullLoader)\n",
    "\n",
    "        # Load the heading angles for this instance from the YAML file\n",
    "        with open(path+'/heading.yaml') as heading_yaml:\n",
    "            headingAngles = yaml.load(heading_yaml, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "        # Set up the result fields for the CSV file\n",
    "        result_fields = [\n",
    "            'name', \n",
    "            'path', \n",
    "            'Obstacles', \n",
    "            'turning_radius', \n",
    "            'continuity_tolerance', \n",
    "            'angle_tolerance', \n",
    "            'node_count', \n",
    "            'edge_count', \n",
    "            'eucLB_NoObstacles', \n",
    "            'dubLB_NoObstacles', \n",
    "            'eucLB', \n",
    "            'eucLB_time', \n",
    "            'dubLB', \n",
    "            'dubLB_time',  \n",
    "            'dubUB', \n",
    "            'dubUB_time']\n",
    "        result_filename = path+'/results_' + time.strftime(\"%Y%m%d-%H%M%S\")+'.csv'\n",
    "\n",
    "        # Open the CSV file and write the result fields to the first row\n",
    "        with open(result_filename, 'w') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(result_fields)\n",
    "\n",
    "            # Loop through each instance path and file\n",
    "            instance_results = []\n",
    "            for (instance_path, dirs, files) in os.walk(path):\n",
    "                for f in files:\n",
    "                    # Check if the file is a pickled Map object\n",
    "                    if f.endswith(\".pkl\") and f.split('_')[0] == 'Map':\n",
    "                        obstacle_count = instance_path.split(\"/\")[-2]\n",
    "                        obstacle_count = obstacle_count.split('_')[1]\n",
    "\n",
    "                        # Load the Map object from the pickled file\n",
    "                        # filepath = instance_path + '/'+f\n",
    "                        filepath = os.path.join(instance_path, f)\n",
    "                        m = open(filepath, 'rb')\n",
    "                        Map = pkl.load(m)\n",
    "\n",
    "                        for rho in radius_list:\n",
    "                            print(\"\\n--------------------------------------------------------------------------\")\n",
    "                            # print(\"Instance: \", instance_path + '/'+ f, \" Radius: \", rho)\n",
    "                            print(\"Tolerances: \", tolerances)\n",
    "\n",
    "                            # Instantiate the Graph_Gstar object\n",
    "                            G = Graph_Gstar(start_conf, end_conf, rho, initial_Sectors, tolerances)\n",
    "\n",
    "                            # Set the image save path\n",
    "                            imgPath = instance_path+'/img'+'/r_'+str(rho)\n",
    "\n",
    "                            # Record the start time\n",
    "                            start_time = time.time()\n",
    "\n",
    "                            # if not os.path.exists(instance_path+'/graphs/G_r'+str(rho)+'.pkl'):\n",
    "                            \n",
    "                            try:\n",
    "                                # Calculate the GstarPaths\n",
    "                                dubLB_path, Map, G = GstarPaths(Map, G, timeLimit, imgPath, heading_restricted, headingAngles)\n",
    "\n",
    "                                # Plot the GstarPaths\n",
    "                                PlotGstar(dubLB_path, G, Map, 'G* Lower Bound Path', save_path=instance_path+'/dub_LB_r'+str(rho), action='save')\n",
    "\n",
    "                                total_time = time.time() - start_time\n",
    "                                print('Time of execution: ', total_time)\n",
    "                            except:\n",
    "                                None\n",
    "\n",
    "\n",
    "                            # Ensure the 'graphs' directory exists\n",
    "                            graphs_path = os.path.join(instance_path, 'graphs')\n",
    "                            if not os.path.exists(graphs_path):\n",
    "                                os.makedirs(graphs_path)\n",
    "\n",
    "                            # Save the graph to a file\n",
    "                            graph_filename = os.path.join(graphs_path, f'G_r{rho}.pkl')\n",
    "                            with open(graph_filename, 'wb') as f:\n",
    "                                pkl.dump(G, f)\n",
    "\n",
    "                            instance_data = [\n",
    "                                f, \n",
    "                                filepath, \n",
    "                                obstacle_count, \n",
    "                                rho, \n",
    "                                tolerances['continuity'], \n",
    "                                tolerances['angular'], \n",
    "                                G.graph.number_of_nodes(), \n",
    "                                G.graph.size(), \n",
    "                                G.eucLB_free, \n",
    "                                G.dubLB_free, \n",
    "                                G.eucLowerBound, \n",
    "                                G.eucLB_time, \n",
    "                                G.dubLowerBound, \n",
    "                                G.dubLB_time, \n",
    "                                G.dubUpperBound, \n",
    "                                G.dubUB_time\n",
    "                                ]\n",
    "                            \n",
    "                            csvwriter.writerow(instance_data)\n",
    "                            \n",
    "                            print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15be763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./instances/map1/obs_10/i_1\n",
      "10\n",
      "Map_i0_o10.pkl\n",
      "./instances/map1/obs_10/i_1/Map_i0_o10.pkl\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Tolerances:  {'continuity': 0.1, 'angular': 15, 'polygon_intersection': 0.7, 'circle_intersection_ratio': 0.5}\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Tolerances:  {'continuity': 0.1, 'angular': 15, 'polygon_intersection': 0.7, 'circle_intersection_ratio': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12904/4158412500.py:49: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
      "  Map = pkl.load(m)\n"
     ]
    }
   ],
   "source": [
    "timeLimit = 600\n",
    "\n",
    "# Set the initial number of sectors and starting and ending configurations\n",
    "initial_Sectors = 3\n",
    "start_conf = (0, 4.5, 0)\n",
    "end_conf = (16, 4.5, 0)\n",
    "\n",
    "# Specify whether the heading is restricted or not\n",
    "heading_restricted = True\n",
    "\n",
    "# Specify the list of radii to use for the algorithm\n",
    "radius_list = [1, 2]\n",
    "\n",
    "path = './instances/map1'\n",
    "\n",
    "\n",
    "with open(path+'/tolerances.yaml') as toleances_yaml:\n",
    "    tolerances = yaml.load(toleances_yaml, Loader=yaml.FullLoader)\n",
    "\n",
    "# Load the heading angles for this instance from the YAML file\n",
    "with open(path+'/heading.yaml') as heading_yaml:\n",
    "    headingAngles = yaml.load(heading_yaml, Loader=yaml.FullLoader)\n",
    "    \n",
    "    \n",
    "result_fields = ['name', 'path', 'Obstacles', 'turning_radius', 'continuity_tolerance', 'angle_tolerance', \\\n",
    "                 'node_count', 'edge_count', 'eucLB_NoObstacles', 'dubLB_NoObstacles', 'eucLB', 'eucLB_time',\\\n",
    "                 'dubLB', 'dubLB_time',  'dubUB', 'dubUB_time']\n",
    "\n",
    "result_filename = path+'/results_' + time.strftime(\"%Y%m%d-%H%M%S\")+'.csv'\n",
    "\n",
    "with open(result_filename, 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(result_fields)\n",
    "    \n",
    "    instance_results = []\n",
    "    \n",
    "    for (instance_path, dirs, files) in os.walk(path):\n",
    "        for f in files:\n",
    "            if f.endswith(\".pkl\") and f.split('_')[0] == 'Map':\n",
    "                print(instance_path)\n",
    "                obstacle_count = instance_path.split(\"/\")[-2]\n",
    "                obstacle_count = obstacle_count.split('_')[1]\n",
    "                print(obstacle_count)\n",
    "                print(f)\n",
    "                \n",
    "                filepath = os.path.join(instance_path, f)\n",
    "                print(filepath)\n",
    "                m = open(filepath, 'rb')\n",
    "                Map = pkl.load(m)\n",
    "                \n",
    "                for rho in radius_list:\n",
    "                    print(\"\\n--------------------------------------------------------------------------\")\n",
    "                    # print(\"Instance: \", instance_path + '/'+ f, \" Radius: \", rho)\n",
    "                    print(\"Tolerances: \", tolerances)\n",
    "                    \n",
    "                    G = Graph_Gstar(start_conf, end_conf, rho, initial_Sectors, tolerances)\n",
    "                    \n",
    "                    imgPath = instance_path+'/img'+'/r_'+str(rho)\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f1a7632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_path.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75572780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G_r3.pkl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98aa7235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G', 'r1.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df282ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startAngle': 90, 'goalAngle': 90}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headingAngles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0701f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
